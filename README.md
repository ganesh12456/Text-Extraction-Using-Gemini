Sure! Here's a comprehensive `README.md` for your Streamlit application that leverages Google's Gemini model for text extraction and description generation based on an uploaded image.

---

# **Text Extraction Using Gemini - Streamlit Application**

This is a **Streamlit** application that allows users to upload an image and receive a description or caption generated by Google's **Gemini model** (part of Google Generative AI). The user can also provide additional prompts to guide the caption generation process. 

## **Features:**
- **Image Upload**: Users can upload images in formats such as JPG, JPEG, or PNG.
- **User Input**: Users can enter a description prompt, which is used by the assistant to generate a more relevant caption or description for the uploaded image.
- **Conversational UI**: A chat-like interface that displays both user messages and assistant responses, making it easy to interact with the model.

---

## **Requirements**

Before running the application, ensure you have the following:

- Python 3.7+
- A Google API key for accessing the **Gemini model**.

### **Install Dependencies**

To install the necessary dependencies, use the following commands:

```bash
pip install streamlit google-generativeai httpx python-dotenv
```

- **streamlit**: Framework for building the web interface.
- **google-generativeai**: Google’s library to interact with the Gemini model.
- **httpx**: HTTP client for making asynchronous requests.
- **python-dotenv**: For loading environment variables from a `.env` file.

---

## **Setup**

### 1. **Get Google API Key**:
   You need to have a **Google API key** to interact with the Gemini model. 

   - Obtain your API key from [Google Cloud](https://console.cloud.google.com/).
   - After creating a project and enabling the **Generative AI API**, you can get your key.

### 2. **Create `.env` File**:
   In the root of your project, create a `.env` file to securely store your Google API key:

   ```bash
   GOOGLE_API_KEY=your_api_key_here
   ```

   Replace `your_api_key_here` with the actual API key.

---

## **How to Run the Application**

1. **Clone the repository** or create a Python script (e.g., `app.py`) and add the provided code into it.
2. **Run the Streamlit app** with the following command:

   ```bash
   streamlit run app.py
   ```

3. Open the URL provided by Streamlit (usually `http://localhost:8501/`) in your web browser to use the application.

---

## **How It Works**

1. **Upload Image**: The user uploads an image in JPG, JPEG, or PNG format.
2. **Provide a Prompt**: After the image is uploaded, the user can enter a description or prompt to guide the assistant in generating a caption or description for the image.
3. **Generate Description**: The assistant uses the **Gemini model** to analyze the image and the user's input to generate a caption or description, which is then displayed in the chat interface.
4. **Conversational UI**: The UI simulates a chat interaction between the user and the assistant, where the assistant provides responses based on the image and user input.

---

## **File Structure**

```
.
├── app.py                 # Main Streamlit application
├── .env                   # Environment variables file for storing Google API Key
├── requirements.txt       # Python dependencies file
└── README.md              # Project documentation (this file)
```

---

## **Code Explanation**

1. **Loading Environment Variables**:
   The `.env` file is loaded using `dotenv` to securely store sensitive information like your Google API key.

2. **Image Upload**:
   The image is uploaded through the `st.file_uploader()` component, and it is converted to base64 format for easy transmission to the Gemini API.

3. **User Input & Prompt**:
   The user can enter a prompt via `st.chat_input()`. This prompt helps the model generate a more relevant description based on the image.

4. **Model Interaction**:
   - The application uses the **Gemini model** to generate a description or caption for the uploaded image, including the user's prompt.
   - The model’s response is displayed in a conversational format using `st.chat_message()`.

5. **Error Handling**:
   In case of an error (e.g., API failure or invalid input), an error message is shown to the user using `st.error()`.

---

## **Example Interaction**

1. **Step 1**: The user uploads an image.
2. **Step 2**: The user enters a description prompt (e.g., "Describe the image").
3. **Step 3**: The assistant generates a description of the image, which is displayed as a response in the chat interface.

---

## **Troubleshooting**

- **API Key Error**: Make sure the Google API key is correctly set in the `.env` file. Check if the key has the correct permissions to access the Gemini model.
- **Model Generation Issues**: If the description generation fails, it may be due to network issues, an invalid API key, or a problem with the uploaded image. Double-check the image format and API key.
- **Streamlit Errors**: If you see errors when running Streamlit, try restarting the app or checking for missing dependencies.

---

## **Contributing**

If you want to contribute to this project, feel free to fork the repository and submit pull requests. Improvements, bug fixes, and additional features are welcome.

---

## **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## **Contact**

For any questions or issues, please contact us at pitaniganesh01@gmail.com.

---

### **Acknowledgements**:

- **Google Generative AI**: For providing the Gemini model API.
- **Streamlit**: For making it easy to create interactive web applications.

---

This `README.md` provides all the necessary instructions to set up, run, and interact with the application. If you have any more questions or need additional features, feel free to reach out!
